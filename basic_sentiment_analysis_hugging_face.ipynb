{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9fc09d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ML\\Transformers\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "905ad44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model = \"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1915a207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'POSITIVE', 'score': 0.9996734857559204}\n",
      "{'label': 'NEGATIVE', 'score': 0.996977686882019}\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"I love playing and watching football!\",\n",
    "    \"I hate when a player misses a penalty!\"\n",
    "]\n",
    "\n",
    "results = sentiment_analyzer(texts)\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75f9343c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'In this course, we will teach you how to use the language of your education.\\n\\n\\n\\n\\n\\n\\n\\n\\nFor students in these courses, you may also learn how to use the language of your education.\\n\\nYou may also learn how to use the language of your education.\\nThe following courses will be taught by a teacher:\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language of your education\\nThe language'}, {'generated_text': 'In this course, we will teach you how to improve and strengthen the skills and power of the brain. We will also teach you how to make it easier for students to read and write and talk in the classroom.\\n\\n\\nThis course is designed to teach you how to make it easier for students to read and write.\\nIt is designed to teach you how to make it easier for students to read and write.\\nIt is a course designed to teach you how to make it easier for students to read and write.\\nIt is a course designed to teach you how to make it easier for students to read and write.\\nIt is a course designed to teach you how to make it easier for students to read and write.\\nIt is a course designed to teach you how to make it easier for students to read and write.'}]\n"
     ]
    }
   ],
   "source": [
    "## different examples of pipeline\n",
    "# pipeline 2\n",
    "\n",
    "\n",
    "generator = pipeline(\"text-generation\", model = \"distilgpt2\")\n",
    "\n",
    "res = generator(\"In this course, we will teach you how to\",\n",
    "                max_length = 30,\n",
    "                num_return_sequences = 2\n",
    "                \n",
    "                )\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71e8e156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'This is a course about transformers', 'labels': ['education', 'business', 'sports'], 'scores': [0.7889325022697449, 0.16456863284111023, 0.04649889096617699]}\n"
     ]
    }
   ],
   "source": [
    "## pipeline 3\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "res2 = classifier(\"This is a course about transformers\",\n",
    "                  candidate_labels = [\"education\",\"sports\",\"business\"]\n",
    "                  )\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3e27e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9768790602684021}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9768790602684021}]\n"
     ]
    }
   ],
   "source": [
    "## Tokenizer and Model\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "res3 = classifier(\"I've been waiting to learn HuggingFace course my whole life.\")\n",
    "\n",
    "print(res3)\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "## Another way \n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer = tokenizer)\n",
    "\n",
    "res4 = classifier(\"I've been waiting to learn HuggingFace course my whole life.\")\n",
    "print(res4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a734743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2478, 1037, 10938, 2121, 2897, 2003, 3722, 1998, 1996, 2190, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['using', 'a', 'transform', '##er', 'network', 'is', 'simple', 'and', 'the', 'best']\n",
      "[2478, 1037, 10938, 2121, 2897, 2003, 3722, 1998, 1996, 2190]\n",
      "using a transformer network is simple and the best\n"
     ]
    }
   ],
   "source": [
    "## Understanding Tokenizer\n",
    "\n",
    "sequence = \"Using a Transformer network is simple and the best\"\n",
    "\n",
    "res = tokenizer(sequence)\n",
    "print(res)\n",
    "\n",
    "tokens = tokenizer.tokenize(sequence)\n",
    "print(tokens)\n",
    "\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(ids)\n",
    "\n",
    "decoded_string = tokenizer.decode(ids)\n",
    "print(decoded_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55e063e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
