{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9fc09d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "905ad44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model = \"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1915a207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'POSITIVE', 'score': 0.9996734857559204}\n",
      "{'label': 'NEGATIVE', 'score': 0.996977686882019}\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"I love playing and watching football!\",\n",
    "    \"I hate when a player misses a penalty!\"\n",
    "]\n",
    "\n",
    "results = sentiment_analyzer(texts)\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75f9343c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'In this course, we will teach you how to create an Arduino for your Arduino.\\n\\n\\n\\nThe Arduino Basics\\nThe first step is to learn the basics of the Arduino. This is the first step. We will be showing you how to use Arduino, and then we will show you how to use it in your Arduino.\\nThe next step is to learn the basics of the Arduino. This is the first step. We will be showing you how to use it in your Arduino. The next step is to learn the basics of the Arduino. This is the first step. We will be showing you how to use it in your Arduino. The next step is to learn the basics of the Arduino. This is the first step. We will be showing you how to use it in your Arduino. The next step is to learn the basics of the Arduino. This is the first step. We will be showing you how to use it in your Arduino. The next step is to learn the basics of the Arduino. This is the first step. We will be showing you how to use it in your Arduino. The next step is to learn the basics of the Arduino. This is the first step. We will be showing you how to use it in your Arduino. The next step is to learn the basics of the Arduino.'}, {'generated_text': 'In this course, we will teach you how to use the power of the internet to change the way people see and use the internet. You can also learn how to use your phone to change the way you see and use the internet to change the way you see and use the internet to change the way you see and use the internet to change the way you see and use the internet to change the way you see and use the internet to change the way you see and use the internet to change the way you see and use the internet to change the way you see and use the internet to change the way you see and use the internet to change the way you see and use the online to change the way you see and use the internet to change the way you see and use the internet to change the way you see and use the internet to change the way you see and use the internet to change the way you see and use the internet to change the way you see and use the internet to change the way you see and use the internet to change the way you see and use the internet to change the way you see and use the internet to change the way you see and use the internet to change the way you see and use the internet to change the way you see and use the internet to change the way you see and use the internet'}]\n"
     ]
    }
   ],
   "source": [
    "## different examples of pipeline\n",
    "# pipeline 2\n",
    "\n",
    "\n",
    "generator = pipeline(\"text-generation\", model = \"distilgpt2\")\n",
    "\n",
    "res = generator(\"In this course, we will teach you how to\",\n",
    "                max_length = 30,\n",
    "                num_return_sequences = 2\n",
    "                \n",
    "                )\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71e8e156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'This is a course about transformers', 'labels': ['education', 'business', 'sports'], 'scores': [0.7889325022697449, 0.16456863284111023, 0.04649889096617699]}\n"
     ]
    }
   ],
   "source": [
    "## pipeline 3\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "res2 = classifier(\"This is a course about transformers\",\n",
    "                  candidate_labels = [\"education\",\"sports\",\"business\"]\n",
    "                  )\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3e27e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9768790602684021}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9768790602684021}]\n"
     ]
    }
   ],
   "source": [
    "## Tokenizer and Model\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "res3 = classifier(\"I've been waiting to learn HuggingFace course my whole life.\")\n",
    "\n",
    "print(res3)\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "## Another way \n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer = tokenizer)\n",
    "\n",
    "res4 = classifier(\"I've been waiting to learn HuggingFace course my whole life.\")\n",
    "print(res4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a734743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2478, 1037, 10938, 2121, 2897, 2003, 3722, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['using', 'a', 'transform', '##er', 'network', 'is', 'simple']\n",
      "[2478, 1037, 10938, 2121, 2897, 2003, 3722]\n",
      "using a transformer network is simple\n"
     ]
    }
   ],
   "source": [
    "## Understanding Tokenizer\n",
    "\n",
    "sequence = \"Using a Transformer network is simple\"\n",
    "\n",
    "res = tokenizer(sequence)\n",
    "print(res)\n",
    "\n",
    "tokens = tokenizer.tokenize(sequence)\n",
    "print(tokens)\n",
    "\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(ids)\n",
    "\n",
    "decoded_string = tokenizer.decode(ids)\n",
    "print(decoded_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55e063e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
